%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Humberto Stein Shiromoto at 2021-12-27 22:30:52 +1100 


%% Saved with string encoding Unicode (UTF-8) 



@book{Tro96,
	abstract = {Although the calculus of variations has ancient origins in questions of Ar- istotle and Zenodoros, its mathematical principles first emerged in the post- calculus investigations of Newton, the Bernoullis, Euler, and Lagrange. Its results now supply fundamental tools of exploration to both mathematicians and those in the applied sciences. (Indeed, the macroscopic statements ob- tained through variational principles may provide the only valid mathemati- cal formulations of many physical laws. ) Because of its classical origins, variational calculus retains the spirit of natural philosophy common to most mathematical investigations prior to this century. The original applications, including the Bernoulli problem of finding the brachistochrone, require opti- mizing (maximizing or minimizing) the mass, force, time, or energy of some physical system under various constraints. The solutions to these problems satisfy related differential equations discovered by Euler and Lagrange, and the variational principles of mechanics (especially that of Hamilton from the last century) show the importance of also considering solutions that just provide stationary behavior for some measure of performance of the system. However, many recent applications do involve optimization, in particular, those concerned with problems in optimal control. Optimal control is the rapidly expanding field developed during the last half-century to analyze optimal behavior of a constrained process that evolves in time according to prescribed laws. Its applications now embrace a variety of new disciplines, including economics and production planning.

# Table of Contents

## Basic Theory

Standard Optimization Problems
Linear Spaces and G{\^a}teaux Variations
Minimization of Convex Functions
The Lemmas of Lagrange and du Bois-Reymond
Local Extrema in Normed Linear Spaces
The Euler-Lagrange Equations

## Advanced Topics

Piecewise C1 Extremal Functions
Variational Principles in Mechanics
Sufficient Conditions for a Minimum

## Optimal Control

Control Problems and Sufficiency Considerations
Necessary Conditions for Optimality},
	author = {J. L. Troutman},
	date-added = {2021-12-27 22:27:34 +1100},
	date-modified = {2021-12-27 22:30:25 +1100},
	doi = {10.1007/978-1-4612-0737-5},
	edition = {2nd},
	keywords = {calculus; convexity; optimal control; linear optimization;},
	publisher = {Springer},
	series = {Undergraduate Texts in Mathematics},
	title = {Variational Calculus and Optimal Control},
	url = {https://doi.org/10.1007/978-1-4612-0737-5},
	year = {1996},
	bdsk-url-1 = {https://doi.org/10.1007/978-1-4612-0737-5}}

@book{Gos15,
	abstract = {Simulation-Based Optimization: Parametric Optimization Techniques and Reinforcement Learning introduces the evolving area of static and dynamic simulation-based optimization. Covered in detail are model-free optimization techniques -- especially designed for those discrete-event, stochastic systems which can be simulated but whose analytical models are difficult to find in closed mathematical forms.

Key features of this revised and improved Second Edition include:

路 Extensive coverage, via step-by-step recipes, of powerful new algorithms for static simulation optimization, including simultaneous perturbation, backtracking adaptive search, and nested partitions, in addition to traditional methods, such as response surfaces, Nelder-Mead search, and meta-heuristics (simulated annealing, tabu search, and genetic algorithms)

路 Detailed coverage of the Bellman equation framework for Markov Decision Processes (MDPs), along with dynamic programming (value and policy iteration) for  discounted, average, and total reward performance metrics

路 An in-depth consideration of dynamic simulation optimization via temporal differences and Reinforcement Learning: Q-Learning, SARSA, and R-SMART algorithms, and policy search, via API, Q-P-Learning, actor-critics, and learning automata

路 A special examination of neural-network-based function approximation for Reinforcement Learning, semi-Markov decision processes (SMDPs), finite-horizon problems, two time scales, case studies for industrial tasks, computer codes (placed online), and convergence proofs, via Banach fixed point theory and Ordinary Differential Equations

Themed around three areas in separate sets of chapters -- Static Simulation Optimization, Reinforcement Learning, and Convergence Analysis -- this book is written for researchers and students in the fields of engineering (industrial, systems, electrical, and computer), operations research, computer science, and applied mathematics.

# Table of Contents

Simulation Basics
Simulation-Based Optimization: An Overview
Parametric Optimization: Response Surfaces and Neural Networks
Parametric Optimization: Stochastic Gradients and Adaptive Search
Control Optimization with Stochastic Dynamic Programming
Control Optimization with Reinforcement Learning
Control Optimization with Stochastic Search
Convergence: Background Material
Convergence Analysis of Parametric Optimization Methods
Convergence Analysis of Control Optimization Methods
Case Studies
},
	author = {A. Gosavi},
	date-added = {2021-12-26 21:42:44 +1100},
	date-modified = {2021-12-26 21:45:45 +1100},
	doi = {10.1007/978-1-4899-7491-4},
	edition = {2nd},
	keywords = {computational operations research; operations research; reinforcement learning; simulation},
	publisher = {Springer},
	series = {Operations Research/Computer Science Interfaces Series},
	title = {Simulation-Based Optimization},
	url = {https://doi.org/10.1007/978-1-4899-7491-4},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1007/978-1-4899-7491-4}}

@book{NocWri06,
	abstract = {Numerical Optimization presents a comprehensive and up-to-date description of the most effective methods in continuous optimization. It responds to the growing interest in optimization in engineering, science, and business by focusing on the methods that are best suited to practical problems.

For this new edition the book has been thoroughly updated throughout. There are new chapters on nonlinear interior methods and derivative-free methods for optimization, both of which are used widely in practice and the focus of much current research. Because of the emphasis on practical methods, as well as the extensive illustrations and exercises, the book is accessible to a wide audience. It can be used as a graduate text in engineering, operations research, mathematics, computer science, and business. It also serves as a handbook for researchers and practitioners in the field. The authors have strived to produce a text that is pleasant to read, informative, and rigorous - one that reveals both the beautiful nature of the discipline and its practical side.

# Table of Contents


Fundamentals of Unconstrained Optimization
Line Search Methods
Trust-Region Methods
Conjugate Gradient Methods
Quasi-Newton Methods
Large-Scale Unconstrained Optimization
Calculating Derivatives
Derivative-Free Optimization
Least-Squares Problems
Nonlinear Equations
Theory of Constrained Optimization
Linear Programming: The Simplex Method
Linear Programming: Interior-Point Methods
Fundamentals of Algorithms for Nonlinear Constrained Optimization
Quadratic Programming
Penalty and Augmented Lagrangian Methods
Sequential Quadratic Programming
Interior-Point Methods for Nonlinear Programming
},
	author = {J. Nocedal and S. Wright},
	date-added = {2021-12-26 21:39:22 +1100},
	date-modified = {2021-12-26 21:41:24 +1100},
	doi = {10.1007/978-0-387-40065-5},
	edition = {2nd},
	keywords = {calculus of variations; quasi-Newton method; linear optimization; nonlinear optimization; operations research; quadratic programming},
	publisher = {Springer},
	series = {Springer Series in Operations Research and Financial Engineering},
	title = {Numerical Optimization},
	url = {https://doi.org/10.1007/978-0-387-40065-5},
	year = {2006},
	bdsk-url-1 = {https://doi.org/10.1007/978-0-387-40065-5}}

@book{Ewi16,
	annote = {Looks promising as it is self contained. Doesn't look very rigorous.},
	author = {G. M. Ewing},
	date-added = {2021-12-23 14:53:00 +1100},
	date-modified = {2021-12-23 14:59:15 +1100},
	publisher = {Dover Publications},
	series = {Dover Books on Mathematics},
	title = {Calculus of Variations with Applications},
	year = {2016}}

@book{PapSte98,
	author = {C. H. Papadimitriou and K. Steiglitz},
	date-added = {2021-12-23 14:48:56 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	publisher = {Dover Publications},
	series = {Dover Books on Computer Science},
	title = {Combinatorial Optimization},
	year = {1998}}

@book{Moc11,
	author = {Jonas Mockus J. Mockus},
	date-added = {2021-12-22 21:53:07 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	doi = {10.1007/978-94-009-0909-0},
	edition = {1},
	keywords = {Global Optimization; Bayesian Optimization},
	publisher = {Springer},
	series = {Mathematics and its Applications},
	title = {Bayesian Approach to Global Optimization},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1007/978-94-009-0909-0}}

@misc{BroCorFre10,
	abstract = {We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences. },
	archiveprefix = {arXiv},
	author = {E. Brochu and V. M. Cora and N. de Freitas},
	date-added = {2021-12-22 21:50:52 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	eprint = {1012.2599},
	keywords = {Bayesian Optimization},
	primaryclass = {cs.LG},
	title = {A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning},
	year = {2010}}

@book{LebClo0312,
	abstract = {This is a book for those who want to understand the main ideas in the theory of optimal problems. It provides a good introduction to classical topics (under the heading of ``the calculus of variations'') and more modern topics (under the heading of ``optimal control''). It employs the language and terminology of functional analysis to discuss and justify the setup of problems that are of great importance in applications. The book is concise and self-contained, and should be suitable for readers with a standard undergraduate background in engineering mathematics.},
	author = {L. P. Lebedev and M. J. Cloud},
	date-added = {2021-12-22 21:43:23 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	doi = {10.1142/5374},
	month = {Dec.},
	publisher = {World Scientific},
	series = {Series on Stability, Vibration and Control of Systems},
	title = {The Calculus of Variations and Functional Analysis},
	volume = {12},
	year = {2003},
	bdsk-url-1 = {https://doi.org/10.1142/5374}}

@book{BonLemGil03,
	abstract = {Combines mathematical developments, description and analysis of algorithms

Selection of algorithms is based on their applicability to real-life problems},
	author = {{J. F.} Bonnans and C. Lemar\'{e}chal and {J. C.} Gilbert and {C. A.} Sagastiz\'{a}bal},
	date-added = {2021-12-22 21:29:55 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	doi = {10.1007/978-3-662-05078-1},
	keywords = {Optimization Algorithms; Interior-point Methods; Linear Optimization; Nonsmooth Optimization; Sequential Quadratic Programming; Algorithm Analysis; Problem Complexity},
	publisher = {Springer},
	series = {Universitext},
	title = {Numerical Optimization},
	year = {2003},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-662-05078-1}}

@book{LueYin16,
	author = {D. G. Luenberger and {Y}. Yinyu},
	date-added = {2021-12-22 21:28:08 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	doi = {10.1007/978-3-319-18842-3},
	keywords = {Linear Programming; Mathematical Programming; Nonlinear Programming; Operations Research; Optimization Models; Semidefinite Programming;},
	publisher = {Springer},
	title = {Linear and {N}onlinear {P}rogramming},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-319-18842-3}}

@book{RocWet98,
	author = {R. T. Rockafellar and R. J.-B. Wets},
	date-added = {2021-12-22 21:25:51 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	doi = {10.1007/978-3-642-02431-3},
	edition = {1},
	keywords = {Convex Analysis; Epi-convergence; Non-smooth Analysis; Variational Analysis},
	publisher = {Springer},
	series = {Grundlehren der mathematischen Wissenschaften},
	title = {Variational Analysis},
	year = {1998},
	bdsk-url-1 = {https://doi.org/10.1007/978-3-642-02431-3}}

@book{CalEl-14,
	author = {G. Calafiore and L. {El Ghaoui}},
	date-added = {2021-12-22 21:24:35 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	doi = {10.1017/CBO9781107279667},
	publisher = {Cambridge University Press},
	rating = {5},
	title = {Optimization Models},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1017/CBO9781107279667}}

@book{BoyVan04,
	author = {S. Boyd and L. Vandenberghe},
	date-added = {2021-12-22 21:21:32 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	publisher = {Cambridge University Press},
	title = {Convex Optimization},
	year = {2004}}

@misc{Bub15,
	archiveprefix = {arXiv},
	author = {S. Bubeck},
	date-added = {2021-12-22 21:19:42 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	eprint = {1405.4980},
	primaryclass = {math.OC},
	title = {Convex Optimization: Algorithms and Complexity},
	year = {2015}}

@book{Lib12,
	abstract = {This textbook offers a concise yet rigorous introduction to calculus of variations and optimal control theory, and is a self-contained resource for graduate students in engineering, applied mathematics, and related subjects. Designed specifically for a one-semester course, the book begins with calculus of variations, preparing the ground for optimal control. It then gives a complete proof of the maximum principle and covers key topics such as the Hamilton-Jacobi-Bellman theory of dynamic programming and linear-quadratic optimal control.},
	author = {D. Liberzon},
	date-added = {2021-12-22 21:14:09 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	publisher = {Princeton University Press},
	rating = {5},
	title = {Calculus of variations and optimial control: A concise introduction},
	year = {2012}}

@book{Cla13,
	abstract = {A self-contained in-depth introduction to functional analysis and the related fields of optimal control and the calculus of variations that is unique in its coverage

Written in a lively and engaging style by a leading specialist

Includes a short course on optimization and nonsmooth analysis

Gives complete proofs of advanced versions of the Pontryagin maximum principle that appear for the first time in a textbook

Contains hundreds of exercises of an original nature, with solutions or hints in many cases},
	author = {F. H. Clarke},
	date-added = {2021-12-22 21:11:58 +1100},
	date-modified = {2021-12-23 14:59:10 +1100},
	doi = {10.1007/978-1-4471-4820-3},
	keywords = {Calculus of Variations; Continuous Optimization; Dynamic Optimization; Functional Analysis; Optimal Control},
	publisher = {Springer},
	rating = {5},
	series = {Graduate Texts in Mathematics},
	title = {Functional Analysis, Calculus of Variations and Optimal Control},
	volume = {264},
	year = {2013},
	bdsk-url-1 = {https://doi.org/10.1007/978-1-4471-4820-3}}
